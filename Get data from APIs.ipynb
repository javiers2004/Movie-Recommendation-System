{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "input_file = 'ml-latest-small/links.csv'\n",
    "output_file = 'movie_info2.csv'\n",
    "log_file = 'request_log.txt'  \n",
    "state_file = 'process_state.json' \n",
    "\n",
    "API_KEYS = [\n",
    "    \"f8e988f2\",\n",
    "    \"555f1493\",\n",
    "    \"b0d221b4\",\n",
    "    \"c86493c7\",\n",
    "    \"7b84cc60\",\n",
    "    \"4e952303\",\n",
    "    \"be7cc8cc\",\n",
    "    \"b3e8365b\",\n",
    "    \"37bb452e\",\n",
    "    \"a30f4ad5\",\n",
    "    \"a30f4ad5\"\n",
    "]\n",
    "current_key_index = 0\n",
    "BASE_URL = \"http://www.omdbapi.com/?\"\n",
    "TMDB_API_KEY = \"tu_tmdb_api_key_aquí\"\n",
    "TMDB_BASE_URL = \"https://api.themoviedb.org/3/movie/\"\n",
    "\n",
    "api_failures = {key: 0 for key in API_KEYS}\n",
    "max_consecutive_failures = 3  \n",
    "max_total_failures = 10 \n",
    "\n",
    "def save_state(current_index, total_ids, processed_ids=None):\n",
    "    state = {\n",
    "        \"last_processed_index\": current_index,\n",
    "        \"total_ids\": total_ids,\n",
    "        \"processed_count\": len(processed_ids) if processed_ids else current_index,\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"current_api_key_index\": current_key_index,\n",
    "        \"processed_ids\": processed_ids if processed_ids else []\n",
    "    }\n",
    "    \n",
    "    with open(state_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(state, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "\n",
    "def load_state():\n",
    "    if os.path.exists(state_file):\n",
    "        try:\n",
    "            with open(state_file, 'r', encoding='utf-8') as f:\n",
    "                state = json.load(f)\n",
    "            \n",
    "            global current_key_index\n",
    "            if 'current_api_key_index' in state:\n",
    "                current_key_index = state['current_api_key_index']\n",
    "                \n",
    "            return state\n",
    "        except Exception as e:\n",
    "            print(f\"Error\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def log_request(imdb_id, api_key, successful):\n",
    "    with open(log_file, 'a', encoding='utf-8') as f:\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        result = \"éxito\" if successful else \"fallo\"\n",
    "        f.write(f\"{timestamp},{imdb_id},{api_key},{result}\\n\")\n",
    "\n",
    "def get_next_api_key():\n",
    "    global current_key_index\n",
    "    current_key_index = (current_key_index + 1) % len(API_KEYS)\n",
    "    return API_KEYS[current_key_index]\n",
    "\n",
    "def check_api_health():\n",
    "    all_keys_failing = all(count >= max_consecutive_failures for count in api_failures.values())\n",
    "    \n",
    "    too_many_total_failures = total_api_failures >= max_total_failures\n",
    "    \n",
    "    return not (all_keys_failing or too_many_total_failures)\n",
    "\n",
    "def get_movie_info_omdb(imdb_id, api_key):\n",
    "    global total_api_failures\n",
    "    \n",
    "    if imdb_id.startswith('tt'):\n",
    "        clean_id = imdb_id\n",
    "    else:\n",
    "        clean_id = f\"tt{imdb_id}\"\n",
    "    \n",
    "    url = f\"{BASE_URL}apikey={api_key}&i={clean_id}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        \n",
    "        if data.get('Response') == 'True':\n",
    "            api_failures[api_key] = 0\n",
    "            log_request(imdb_id, api_key, True)\n",
    "            return data\n",
    "        else:\n",
    "            error = data.get('Error', 'Desconocido')\n",
    "            api_failures[api_key] += 1\n",
    "            total_api_failures += 1\n",
    "            \n",
    "            if \"exceeded\" in error.lower() or \"limit\" in error.lower():\n",
    "                return None\n",
    "                \n",
    "            log_request(imdb_id, api_key, False)\n",
    "            print(f\"Error\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        api_failures[api_key] += 1\n",
    "        total_api_failures += 1\n",
    "        log_request(imdb_id, api_key, False)\n",
    "        print(f\"Error en solicitud para ID {imdb_id}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_movie_info_tmdb(imdb_id):\n",
    "    if imdb_id.startswith('tt'):\n",
    "        clean_id = imdb_id\n",
    "    else:\n",
    "        clean_id = f\"tt{imdb_id}\"\n",
    "    \n",
    "    url = f\"{TMDB_BASE_URL}find/{clean_id}?api_key={TMDB_API_KEY}&external_source=imdb_id\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        find_data = response.json()\n",
    "        \n",
    "        movie_results = find_data.get('movie_results', [])\n",
    "        if movie_results and len(movie_results) > 0:\n",
    "            movie_id = movie_results[0]['id']\n",
    "            \n",
    "            details_url = f\"{TMDB_BASE_URL}{movie_id}?api_key={TMDB_API_KEY}&append_to_response=credits,keywords\"\n",
    "            details_response = requests.get(details_url)\n",
    "            movie_data = details_response.json()\n",
    "            \n",
    "            adapted_data = {\n",
    "                'imdbID': clean_id,\n",
    "                'Title': movie_data.get('title', ''),\n",
    "                'Year': movie_data.get('release_date', '')[:4] if movie_data.get('release_date') else '',\n",
    "                'Plot': movie_data.get('overview', ''),\n",
    "                'imdbRating': str(movie_data.get('vote_average', '')),\n",
    "                'Runtime': f\"{movie_data.get('runtime', '')} min\",\n",
    "                'Genre': ', '.join([g['name'] for g in movie_data.get('genres', [])]),\n",
    "                'Director': ', '.join([c['name'] for c in movie_data.get('credits', {}).get('crew', []) if c.get('job') == 'Director']),\n",
    "                'Actors': ', '.join([c['name'] for c in movie_data.get('credits', {}).get('cast', [])[:5]]),\n",
    "                'Language': movie_data.get('original_language', '').upper(),\n",
    "                'Country': ', '.join([c['name'] for c in movie_data.get('production_countries', [])]),\n",
    "                'Source': 'TMDb'  \n",
    "            }\n",
    "            return adapted_data\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error\")\n",
    "        return None\n",
    "\n",
    "def get_movie_info(imdb_id):\n",
    "    if not check_api_health():\n",
    "        return \"API_FAILURE\"  \n",
    "    api_key = API_KEYS[current_key_index]\n",
    "    data = get_movie_info_omdb(imdb_id, api_key)\n",
    "    \n",
    "    attempts = 0\n",
    "    while data is None and attempts < len(API_KEYS):\n",
    "        api_key = get_next_api_key()\n",
    "        data = get_movie_info_omdb(imdb_id, api_key)\n",
    "        attempts += 1\n",
    "    \n",
    "    if data is None and TMDB_API_KEY:\n",
    "        data = get_movie_info_tmdb(imdb_id)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def init_csv_file(fieldnames):\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "def append_to_csv(movie_data, fieldnames):\n",
    "    filtered_data = {k: v for k, v in movie_data.items() if k in fieldnames}\n",
    "    \n",
    "    with open(output_file, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writerow(filtered_data)\n",
    "\n",
    "def get_all_fields(movies_data):\n",
    "    all_fields = set()\n",
    "    for movie in movies_data:\n",
    "        if isinstance(movie, dict):\n",
    "            all_fields.update(movie.keys())\n",
    "    \n",
    "    fieldnames = ['imdbID'] if 'imdbID' in all_fields else []\n",
    "    fieldnames.extend(sorted([f for f in all_fields if f != 'imdbID']))\n",
    "    return fieldnames\n",
    "\n",
    "def load_processed_ids():\n",
    "    processed_ids = []\n",
    "    if os.path.exists(output_file):\n",
    "        try:\n",
    "            with open(output_file, 'r', encoding='utf-8') as csvfile:\n",
    "                reader = csv.DictReader(csvfile)\n",
    "                for row in reader:\n",
    "                    if 'imdbID' in row:\n",
    "                        processed_ids.append(row['imdbID'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error\")\n",
    "    return processed_ids\n",
    "\n",
    "def process_in_batches(imdb_ids, start_index=0, processed_ids=None):\n",
    "    batch_size = 500  \n",
    "    pause_minutes = 0  \n",
    "    \n",
    "    if processed_ids is None:\n",
    "        processed_ids = load_processed_ids()\n",
    "    \n",
    "    total_ids = len(imdb_ids)\n",
    "    \n",
    "    remaining_ids = [id for id in imdb_ids[start_index:] if id not in processed_ids]\n",
    "    total_batches = (len(remaining_ids) + batch_size - 1) // batch_size\n",
    "    \n",
    "    sample_size = min(10, len(remaining_ids))\n",
    "    sample_data = []\n",
    "    \n",
    "    for i in range(sample_size):\n",
    "        if i < len(remaining_ids):\n",
    "            movie_data = get_movie_info(remaining_ids[i])\n",
    "            if movie_data and isinstance(movie_data, dict):\n",
    "                sample_data.append(movie_data)\n",
    "    \n",
    "    all_fields = get_all_fields(sample_data)\n",
    "    \n",
    "    if not os.path.exists(output_file) or os.path.getsize(output_file) == 0:\n",
    "        init_csv_file(all_fields)\n",
    "    \n",
    "    current_batch = 0\n",
    "    for i in range(0, len(remaining_ids), batch_size):\n",
    "        current_batch += 1\n",
    "        batch = remaining_ids[i:i+batch_size]\n",
    "        current_global_index = start_index + i\n",
    "        \n",
    "        for idx, imdb_id in enumerate(tqdm(batch, desc=f\"Lote {current_batch}\")):\n",
    "            movie_data = get_movie_info(imdb_id)\n",
    "            \n",
    "            if movie_data == \"API_FAILURE\":\n",
    "\n",
    "                current_index = current_global_index + idx\n",
    "                \n",
    "                save_state(current_index, total_ids, processed_ids)\n",
    "                \n",
    "                return\n",
    "            \n",
    "            if movie_data and isinstance(movie_data, dict):\n",
    "                append_to_csv(movie_data, all_fields)\n",
    "                processed_ids.append(imdb_id)\n",
    "        \n",
    "        save_state(current_global_index + len(batch), total_ids, processed_ids)\n",
    "        \n",
    "        if current_batch < total_batches:\n",
    "            pause_until = datetime.now() + timedelta(minutes=pause_minutes)\n",
    "            time.sleep(pause_minutes * 60)\n",
    "    \n",
    "\n",
    "imdb_ids = []\n",
    "try:\n",
    "    with open(input_file, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            if 'imdbId' in row:\n",
    "                imdb_ids.append(row['imdbId'])\n",
    "            elif 'tmdbId' in row:\n",
    "                imdb_ids.append(row['tmdbId'])\n",
    "except Exception as e:\n",
    "    sys.exit(1)\n",
    "\n",
    "previous_state = load_state()\n",
    "start_index = 0\n",
    "processed_ids = []\n",
    "\n",
    "if previous_state:\n",
    "    start_index = previous_state.get('last_processed_index', 0)\n",
    "    if 'processed_ids' in previous_state:\n",
    "        processed_ids = previous_state.get('processed_ids', [])\n",
    "\n",
    "process_in_batches(imdb_ids, start_index, processed_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "class MovieInfoScraper:\n",
    "    def __init__(self, input_file, output_file, tmdb_api_key):\n",
    "        self.input_file = input_file\n",
    "        self.output_file = output_file\n",
    "        self.tmdb_api_key = tmdb_api_key\n",
    "        self.progress_file = 'movie_info_progress.json'\n",
    "        \n",
    "        logging.basicConfig(\n",
    "            filename='movie_scraper.log', \n",
    "            level=logging.INFO, \n",
    "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def load_progress(self):\n",
    "        if os.path.exists(self.progress_file):\n",
    "            with open(self.progress_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "        return {'processed_ids': [], 'last_processed_index': -1}\n",
    "    \n",
    "    def save_progress(self, processed_ids, last_processed_index):\n",
    "        progress = {\n",
    "            'processed_ids': processed_ids,\n",
    "            'last_processed_index': last_processed_index\n",
    "        }\n",
    "        with open(self.progress_file, 'w') as f:\n",
    "            json.dump(progress, f)\n",
    "    \n",
    "    def fetch_movie_details(self, tmdb_id):\n",
    "\n",
    "        try:\n",
    "            movie_url = f\"https://api.themoviedb.org/3/movie/{tmdb_id}?api_key={self.tmdb_api_key}\"\n",
    "            movie_response = requests.get(movie_url)\n",
    "            movie_data = movie_response.json()\n",
    "\n",
    "            movie_info = {\n",
    "                'tmdbId': tmdb_id,\n",
    "                'title': movie_data.get('title', 'N/A'),\n",
    "                'rating': movie_data.get('vote_average', 'N/A'),\n",
    "                'release_date': movie_data.get('release_date', 'N/A'),\n",
    "                'original_language': movie_data.get('original_language', 'N/A'),\n",
    "                'origin_country': movie_data.get('production_countries', ['N/A'])[0] if movie_data.get('production_countries') else 'N/A',\n",
    "                'votes': movie_data.get('vote_count', 'N/A'),\n",
    "                'budget': movie_data.get('budget', 'N/A'),\n",
    "                'revenue': movie_data.get('revenue', 'N/A'),\n",
    "                'runtime': movie_data.get('runtime', 'N/A')\n",
    "            }\n",
    "\n",
    "            return movie_info\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error fetching details for movie {tmdb_id}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def scrape_movies(self, max_retries=3):\n",
    "        links_df = pd.read_csv(self.input_file)\n",
    "        \n",
    "        progress = self.load_progress()\n",
    "        processed_ids = progress['processed_ids']\n",
    "        start_index = progress['last_processed_index'] + 1\n",
    "        \n",
    "        if os.path.exists(self.output_file):\n",
    "            output_df = pd.read_csv(self.output_file)\n",
    "        else:\n",
    "            output_df = pd.DataFrame(columns=[\n",
    "                'tmdbId', 'title', 'rating', 'release_date', \n",
    "                'original_language', 'origin_country', 'votes', \n",
    "                'budget', 'revenue', 'runtime'\n",
    "            ])\n",
    "        \n",
    "        for index in range(start_index, len(links_df)):\n",
    "            try:\n",
    "                tmdb_id = int(links_df.iloc[index]['tmdbId'])\n",
    "                \n",
    "                if tmdb_id in processed_ids:\n",
    "                    continue\n",
    "                \n",
    "                movie_info = None\n",
    "                for attempt in range(max_retries):\n",
    "                    movie_info = self.fetch_movie_details(tmdb_id)\n",
    "                    if movie_info:\n",
    "                        break\n",
    "                \n",
    "                if movie_info:\n",
    "                    new_row = pd.DataFrame([movie_info])\n",
    "                    output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "                    output_df.to_csv(self.output_file, index=False)\n",
    "                    \n",
    "                    processed_ids.append(tmdb_id)\n",
    "                    self.save_progress(processed_ids, index)\n",
    "                \n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error general procesando índice {index}: {e}\")\n",
    "        \n",
    "        self.logger.info(\"Scraping de películas completado\")\n",
    "\n",
    "scraper = MovieInfoScraper(\n",
    "    input_file='ml-latest-small/links.csv', \n",
    "    output_file='movie_info.csv', \n",
    "    tmdb_api_key='c768da44d48e2d1706a2451e62972bad'\n",
    ")\n",
    "scraper.scrape_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo limpio guardado como movie_info_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"movie_info2.csv\")\n",
    "df_cleaned = df.drop_duplicates(subset=[\"imdbID\"], keep=\"first\")\n",
    "df_cleaned.to_csv(\"movie_info_cleaned.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
